## 术语了解
LLM large language model  大语言模型
prompt：提示器，给ai模型回答问题做限制

语义：

向量
> 简单理解就是：向量是一个数值数组，通常用于表示数据点的特征或状态， 将知识库的资源(文件、文档等等)通过拆分，embedding成一个个向量存放到向量db中(可以是es等其他的向量数据库)

召回 (召回知识库中的数据)
> 目的是匹配到相识的知识库中的数据返回
> 将用户的请求embedding 成向量，然后到向量db中匹配，去top-k，拿到最匹配的数据返回 -- (余弦相似法)


sentence embedding: 基于句子的方式生成向量
> 在某些业务场景下，通过sentence embedding的方式生成的向量在匹配的时候，可能无法区分业务概览，所以需要自定义
> sentence embedding 是基于静态文件的方式处理的，但是某些业务场景是一个实时动态的数据

自定义RAG 向量知识库，根据业务特征


构建RAG的知识库：
```text
基于cmdb的维度服务，将维度服务的数据按照元数据的方式写入到es中(将es作为向量数据库)
```

MCP: MCP提供的tool的具体实现，就是通过调用RAG知识库中的数据实现
```text
cmdb 只是部分数据
api指标数据，策略数据，告警指标数据，这些都需要通过业务数据转换 -- 形成数据资产为MCP提供服务
```

### 理解AI的思考过程 -- 一步步尝试的过程
比如我想查询图书馆中，西游记这本书的受欢迎程度

分析过程
```text
1、查询图书馆，西游记这本书的进货记录 （进货时间、进货数量）
2、查看西游记这本书最近三个月的借出记录(借出时间、归还时间、借书人，借书人的年龄区间)和售卖记录(卖出数量、购买人的年龄区间、是否是图书馆会员)
3、西游记这边书的购买评价
4、总结输出
```

### AI验证中遇到的问题
```text
1、模型幻觉问题：AI可能会伪造MCP的tool的返回结果，从而给人错误的信息
2、会对复杂的输出中提取的时候，没有凑成精确的参数值传入到下一个步骤内
3、还会解析返回里不存在的东西 （可能是LLM自己补充的）
4、存在调用不存在的MCP的tool的情况
5、过长上下文或者promt的时候，可能会不按照prompt遵循调用
6、工具调用混乱问题  -- 这个可能是因为向量匹配度不够精确导致，比如question生成的向量和多个tool描述的向量都相近(tool的描述比较相似)
7、过多步骤下模型调用倾向混乱的问题 -- 模型会多次判断，导致判断过多
```




### 工具实现

#### LangChain

#### LlamaIndex


### RAG
https://zhuanlan.zhihu.com/p/675509396






### agent


### mcp

#### MCP-GO
