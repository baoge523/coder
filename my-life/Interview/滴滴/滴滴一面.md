
### 自我介绍和项目介绍

DDD模式在开发中的运用
```text
1、业务的分层：entity usecase 
2、与传统的mvc开发模式的比较，功能服务更内聚、能更好的评估变更的影响范围
3、常见在开发中的配置类，各个组件使用到的配置entity应该在自己的组件内维护，而不是使用一个统一的config package使用
4、对于访问db的entity类，应该包含所有操作该对应数据的操作，也不是上移到service层（usecase）层，对应的service层应该聚焦在业务逻辑处理
```


golang的map
是否是线程安全的 map sync.Map 其他的map

map 的读写是否存在线程安全问题、map 的线程不安全体现在哪里
```text
首先： 原生的map并发访问都存在线程安全问题
并发写-写：内部需要维护hash表，可能导致hash表元数据不一致；可能破坏hash表的内部结构（如桶指针、溢出链等），最终可能导致panic
并发读-写：可能获取到部分更新的数据（脏数据）、可能导致读取到不一致的map状态、在某些情况下可能出发panic
扩容时的并发操作不安全：扩容过程中，并发操作可能获取到无效的内存地址、几乎一定会导致 fatal error: concurrent map read and map write
并发删除：删除操作实际上是写操作、与读操作并发时同样会产生竞争、可能读取到已经删除了的数据
```

sync.Map
```text
内部维护了一个
read map：  用于读  - cas的方式读
dirty map： 用于写 - mutex的方式写


sync.Map大量使用 atomic包的原子操作来管理
  指向 read map 的指针
  修改计数（misses）
  其他状态标志
  
通过使用mutex来保护
  dirty map 的访问
  read 和 dirty 之间的数据迁移
  新键的首次写入
  
读操作
    无锁：如果键存在于 read map 中，直接原子读取
    加锁：如果键不在 read map 中（miss），则：
        1.获取 mutex 锁
        2.检查 dirty map 
        3.更新 misses 计数
        4.必要时触发 read 和 dirty 的交换
        5.释放锁
写操作
    首次写入新键：
        1.获取 mutex 锁
        2.写入 dirty map
        3.释放锁
    更新已有键：
        如果键在 read map 中，尝试原子 CAS 更新
        失败则获取 mutex 锁并更新 dirty map

删除操作
    read 中存在：标记为删除（expunged）
    read 中不存在：获取 mutex 锁后操作 dirty map


sync.Map的性能：
  1、读优先，绝大多数的读操作，都是走cas的方式访问
  2、延迟写入：新键首次写入 dirty map，不立即更新 read
  3、miss 计数触发同步：当 read miss 达到一定次数（len(dirty)），触发 read 和 dirty 的同步
  4、双检查机制：在加锁前后都进行检查，减少锁竞争
 
锁粒度：因为sync.Map是使用的同一个mutex，所以是锁的整个map（dirty map）但是在获取锁之前，需要判断是否在read map中存在
  写-写：锁整个dirty map
  写-读：如果读的数据在read map中，不加锁；写加锁；否则都加锁
  读-读：如果都在read map中，不加锁；否则加锁互斥
```



内存泄露如何排查
```text
哪些工具
pprof工具，go tool查看  --分析堆内存
gc 判断
监控系统 prometheus + grafana

内存泄露的原因：
1、goroutine 泄漏
2、全局变量的累积，全局的map、slice只增不减
3、资源泄露，使用后未关闭，比如文件、数据库连接等
4、定时任务未正常关闭
5、引用未及时释放，比如大对象，循环依赖等问题
6、cgo的泄露、错误的defer操作
```

cpu使用率异常如何排查

考虑分析栈内存，goroutine等信息

火焰图还能排查哪些问题


在子携程中抛出panic，会影响到父携程吗？
```text
答案是，肯定的；不做处理的panic会导致程序退出

处理panic的方式，使用recover来捕获，并将其封装成普通的error

业务处理，不直接创建go func(){}() 的方式执行，而是通过自定义的具备捕获行为的创建goroutine的方式
```

channel的使用场景：
1、异步任务处理
2、信号通知


数据的表设计
```text
索引设计
主键索引 -- 使用
字段设计 -- 最小化原则
表与表之间的关联关系
```

数据库的分表设计
```text
用户表： 用户ID
订单表： 订单ID

从用户量级上面（业务场景）考虑，而从考虑如何使用user_id分库还是通过车主id分库
如果想通过车主id查询怎么办，通过另外的索引（车主id-订单id）分表；  什么时候写入呢？ 业务上面双写 --- 可能有不一致的风险，使用2pc、3pc、tcc等方式保证，或者通过最终一致性来保证
提供查询接口，判断是否数据不一致

```

### 编程题，交替打印
妈的，有个死锁问题， 原因是，第二个goroutine没有判断写入channel的条件
```go
nums := []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}

	c1 := make(chan struct{})
	c2 := make(chan struct{})

	w := sync.WaitGroup{}

	w.Add(2)

	go func() {
		defer w.Done()

		for i := 0; i < len(nums); {
			<-c1
			fmt.Printf("%d  ", nums[i])
			c2 <- struct{}{}
			i += 2
		}

	}()

	go func() {
		defer w.Done()

		for i := 1; i < len(nums); {
			<-c2
			fmt.Printf("%d  ", nums[i])
			if i+2 < len(nums) {  // 这里需要判断一下，不然有死锁问题 -- 保证最后一次不发送
				c1 <- struct{}{}
			}
			i += 2
		}

	}()

	// start
	c1 <- struct{}{}
	w.Wait()

	close(c1)
	close(c2)
```

### 反问
乘客端的所有流量入口服务

流量突涨时的处理方式， 限流、水平扩容
业务分表是基于用户id来分表的吗