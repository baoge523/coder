### 自我介绍+项目介绍

百度主要是做零信任的，考察的是我零信任的功底 -- 哎，都快忘记了

oauth2.0（授权）的认证流程：
OIDC（基于oauth2.0的认证协议）：
cas

oauth2.0:  （client 前端浏览器做，code会暴露在浏览器地址中）会话 换 code； （client 后端服务，不会暴露在浏览器中）code 换token， token 换用户资源

### 零信任的项目介绍
数据面： 数据接入  数据源：hr、ldap 等系统

基于元数据的方式（json的方式），可以配置的创建数据库表和数据库索引

控制面： 认证（sso）、比如oidc、oauth2.0


### redis 分布式锁的使用
通过使用 redis的 setnx来实现redis 的分布式锁，来达到控制多节点并发访问资源控制的目的

但是redis的setnx 并不一定是可靠的，redis的setnx只保证了单redis下是可靠的，但是在集群下（主从的时候）就不一定是可靠的了
```text
场景：
现在有一个redis集群，1主4从，同时有三个服务pod与该redis集群通信访问

pod1 通过setnx 在redis 的master节点上设置了一个key，但是redis主从之间的同步是异步的，所以可能在redis的master 还没有同步到salve上，master就挂了
此时salve(未接收到同步的)竞选master成功，但是它并没有设置锁的key

现在pod2，通过setnx 在redis 的master上设置key也能成功，此时的pod1和pod2都拿到了分布式锁，导致并发访问资源存在问题

----解决方式 ----
1、redis使用单节点，但是会有redis单点问题
2、red lock，这也是redis的设计者提出的解决方案
  表示setnx时，会同时向多个redis节点发起请求，当超过半数的都成功时，才表示setnx成功 -- 有点raft那味了
  
  锁的释放：客户端向所有 Redis 节点发送释放锁请求；使用 Lua 脚本确保只有锁的持有者才能释放锁（比较随机值）

```

什么情况下，存在一个redis的key被一个服务持续持有
```text
1、业务代码层面问题，设置一个key后，没有设置ttl，同时在使用完后，没有删除该key
2、业务设置key没有设置ttl，然后业务异常挂掉，导致redis的key不会正常被释放
3、业务逻辑成为，设置了ttl，但是存在一个后台任务在ttl失效前定时续期

---解决方式----
1、保持良好的开发习惯，在设置key时，加上ttl，当要key要过期时，业务还处理不完，就给该key续期
2、设置了ttl，会保证在系统异常挂掉时，有能力失效掉该key
```


### kafka的使用和调优 -- 具体到使用了哪些调优手段
业务中对kafka的使用场景：
```text
1、默认策略绑定实例时，异步消峰，统一下游消费处理，使用kafka，基于kafka分区的顺序性，解决顺序处理问题、通过根据业务将大用户的数据分流到不同的kafka 的topic中
2、事件总线中，消费kafka中的事件信息，消费者中包含了生产者，该生产者用于将异常消费的数据重新写回kafka；存在的问题时，当kafka发生重平衡的时候，会导致生产者未优雅关闭，导致kafka的连接持续上涨，资源泄露，直到监控告警
```

重平衡时，消费者绑定对于的kafka分区的策略有哪些：
```text
RangeAssignor（范围分配器）

RoundRobinAssignor（轮询分配器）

StickyAssignor（粘性分配器）： 不会全局的分区重新分配，只会讲新的分区，或者下线的消费者消费的分区拿来重新分配

Cooperative Sticky Assignor（合作式粘性分配器）
    这是 StickyAssignor 的增强版，是现代 Kafka 版本（尤其是从 2.4+ 开始）推荐使用的策略
    合作式策略（Cooperative）：重平衡分为多个步骤。消费者不需要立即放弃全部分区。协调器可以先进行一轮分配，让消费者先放弃那些确定需要移走的分区，其他分区可以继续处理消息。然后再进行下一轮调整，直到达成最终平衡状态。
```

kafka 生产者的调优参数：
```text
Producer 调优的核心目标是在 高吞吐量、低延迟 和 消息可靠性 之间找到平衡

核心可靠性参数：
ack：
    作用：   指定必须有多少个分区副本收到消息，生产者才认为消息发送成功
    可选值： 
        ack=0：      生产者不等待任何确认。吞吐量最高，延迟最低，但可能丢失消息。适用于对可靠性要求极低的日志收集场景
        ack=1(默认)： 领导者副本写入本地日志后就认为成功。在吞吐量、延迟和可靠性之间取得平衡。如果领导者宕机且尚未复制，消息可能丢失
        ack=all：    等待所有同步副本（ISR）都确认收到消息。最可靠，但吞吐量最低，延迟最高。结合 min.insync.replicas使用。
调优建议：
  如果需要保证数据的可靠性，那么需要将ack设置成all
  
min.insync.replicas：
    作用： 配合 acks=all使用，指定 Broker 端要求的最小同步副本数
    
retries和 retry.backoff.ms：
    作用： 生产者发送消息失败后的重试次数（retries）和每次重试之间的等待时间（retry.backoff.ms）
    


吞吐量与延迟参数：
buffer.memory：
    作用： 生产者消息缓冲池的大小。如果发送速度大于发送到服务器的速度，可能会导致缓冲区耗尽，此时 send()方法调用将被阻塞或抛出异常

batch.size和 linger.ms：
    作用： 两者共同控制生产者发送消息的批处理行为
    batch.size： 当某个分区的批次数据达到这个大小（默认 16KB）时，会立即发送。
    linger.ms： 生产者等待多长时间（默认 0ms）后发送一个批次，即使批次没满
    
compression.type：
    作用： 消息批次的压缩类型（如 gzip, lz4, snappy, zstd）
    
    
    
其他重要参数：
max.request.size：
    作用： 控制生产者发送的单个请求的最大大小
```


kafka 消费者的调优参数：
```text
核心消费逻辑参数
    auto.offset.reset
        作用： 当消费者在Broker没有初始偏移量或偏移量失效（如数据被删除）时的行为
    enable.auto.commit
        作用： 是否让消费者自动提交偏移量。
        设置为 false并由应用程序手动提交偏移量是最佳实践。

吞吐量与性能参数
    fetch.min.bytes和 fetch.max.wait.ms
        作用： 两者共同控制消费者从Broker拉取数据的批次大小。
    
    max.poll.records
    
防止Rebalance与活锁的关键参数
    session.timeout.ms
    heartbeat.interval.ms
    max.poll.interval.ms

```


### 数据库 mysql层面的

数据库的优化中，考虑优化方向
0、将慢sql拿来做explain查看，看是否用到索引、扫描的行数、是否有where过滤、文件排序、临时表等信息
1、数据库的查询，尽量走索引
2、大sql，尽量拆分成更小的sql
3、select 查询时，不要盲目使用 *，而是查询需要的字段，应该如果需要的字段在二级索引上，可以通过索引覆盖，优化查询
4、查询的使用最好使用limit，因为limit会在满足数量后就退出，而不会查询大量的数据
5、二级索引是会保护主键索引的，所以在索引的创建上面，避免创建相同功能的索引，索引本身也会占用磁盘空间
6、优化 JOIN 操作；小表驱动大表，连表条件需要走索引
7、优化排序 (ORDER BY) 和分组 (GROUP BY)，尽可能的走索引，避免昂贵的文件排序、临时表



索引最左匹配原则
复合索引的最左匹配原则：
```text
比如： A B C 的索引， A AB ABC 都可以走该索引，但是具体的索引选择需要看mysql的索引优化器的选择
```

string类型的索引，也有最左匹配原则：
```text
字符串左前缀匹配规则
```


mysql 为什么选择b+树作为索引的数据结构
```text
根据mysql的业务特性：
  1、需要执行范围查询
  2、尽可能更少的io、同时一次io拿尽可能多的数据
  3、b+树的叶子节点是顺序存储的，可以更好的厉害cpu缓存
  
和数组（二分）、hash（精确匹配、不支持范围查询）、二叉树（数据量，层级高，io次数多）、b树（非叶子节点也包含数据，io次数多）、跳表（层级多，io次数多，同时跳表适合是内存中的数据结构-redis的zset）
```


数据库设计：
```text
1、选择合适的数据类型
   更小通常更好，使用能正确存储数据的最小类型
   使用 INT而非 VARCHAR存储数字或枚举值
   NULL会增加索引和查询的复杂性，尽量定义列为 NOT NULL
   
2、规范化与反规范化  --根据场景评估
   规范化(尽量不存在冗余数据): 但是这样会导致更多的join操作
   反规范化(存在冗余数据)：减少join，但是存在冗余数据，可能导致数据不一致的风险 -- 避免多表 JOIN，但会增加数据一致性的维护成本

3、表设计
    推荐使用自增主键，可以提高插入性能并减少页分裂
    对于存储大量文本的字段，考虑使用垂直分表，将不常用的“大字段”拆分到另一张表中，主表只存核心信息和外键
```

系统与架构优化：
```text
1、升级硬件、修改mysql的配置：比如 innodb_buffer_pool_size： InnoDB 缓冲池大小、innodb_log_file_size： Redo Log 大小、max_connections： 最大连接数

2、读写分离

3、分库分表
   垂直分表：将一张宽表按列拆分成多个小表
   水平分表（Sharding）：将一张表的数据按某种规则（如范围、Hash）分布到多个数据库或表中。这是应对海量数据的最有效手段，但会极大增加应用层的复杂度

4、使用缓存
```

### golang 层面的

GMP的运行模式
```text

```

### 腾讯云业务

策略是如何同步的：
```text
控制台的策略创建，会通过监听mysql binlog（canal） + kafka 同步到 告警检测服务中
同步器的方式有： 增量同步 和全量同步两种方式

为了保证数据的一致性，同步器的实现使用单线程 + 单kafka的topic，单分区的方式 实现
 - 里面包含了业务逻辑、网络io、磁盘io等操作，效率很慢

举例说明了一条delete sql操作，带来的同步器告警问题

delete sql执行时，没有评估处理的数据条数，导致删除了接近20w数据，同步器处理不过来，Kafka消息积压 -- 产生告警

解决方式：
  手动的启动全量同步，全量同步（多线程）完成后，增量同步（单线程）的就不会有业务的比较、网络io、磁盘io等其他的开销，只需要比较一个version(版本号)即可

```


### 算法题 - 手写一个快排（原地排序） -- 快排是不稳定的排序

快排的思路：


### 问答环节
业务是零信任网关

使用量上面是内部和外部都会用
正常内部使用的话，就是几千的qps
外部和内部的话，就是几十万的qps


