## 2024-mr

### kafka句柄泄露，导致连接无法正常断开，一种直观的现象就是kafka的连接数量增多，且高居不下

原因是，在consumer中构建了一个reproducer对象，该对象在consumer初始化异常时，没有正确的关闭，导致连接一直存在
为什么会初始化异常呢？
原因是：当kafka的group重平衡时，会重新创建consumer，而在销毁consumer的时候，没有优雅的销毁reproducer对象导致


golang中的kafka
```text
github.com/Shopify/sarama v1.38.1
```

```go
// 拿到运行时(分配后的主题和分区)-- 可能没有包含某个主题，后新增的分区信息
// ConsumerGroupClaim processes Kafka messages from a given topic and partition within a consumer group.
type ConsumerGroupClaim interface {
	// Topic returns the consumed topic name.
	Topic() string

	// Partition returns the consumed partition.
	Partition() int32

}

// 拿到指定主题下的分区信息
// ConsumerGroupSession represents a consumer group member session.
type ConsumerGroupSession interface {
// Claims returns information about the claimed partitions by topic.
Claims() map[string][]int32
}
```
todo:

需要补全：sarama的使用方式
编码构造方式:
consumerFactory 包含了consumer所有的信息，然后通过配置构建出consumer对象
最终是：构建sarama的config，创建sarama的consumer的client

### 需要判断一个操作是否需要在事务内
1、命名规范，一定要有明确的含义，如果含义不明确会导致维护困难
2、判断一个操作是否需要在一个事务内
```text
目前都是通过gorm的本地事务处理的
当在一个事务内，通过接口调用其他服务，然后其他服务会通过关键信息(id)查询，会查询不到数据，因为主调方的本地事务未提交

解决方式：
1、引入分布式事务，但繁琐、回滚链路长
2、将调用操作移除到事务之外， 这里需要评估调用其他服务和调用方的本地事务中的数据，
            是不是强关系，如果是强关系，如果调用方法失败了，需要逆操作；不然会有数据不一致；
                       如果不是强关系，就会有脏数据(不完全正确的数据)
3、在事务之内，只不过调用接口时，把所有的数据都带带过去(避免被调用的接口查询数据库)

```

### 一个方法中多出返回err时，需要通过fmt.Errorf携带更多的上下文，方便出错时定位问题
1、方法中多处返回err时，需要通过fmt.Errorf携带更多的上下文信息
2、定义变量时，变量的作用域需要尽可能的小
```go
// good
if name, ok := extra["nameKey"].(string); ok {
    senderParam.Name = name
}

// bad
 name, ok := extra["nameKey"].(string);
 if ok {
   senderParam.Name = name
 }
```
3、对一些异常，比如json解析异常时，会跳过，而不是中断业务执行时，需要将该信息上报，留下业务痕迹(不然都无法感知)
```text
比如: 指标上报、打印日志等等
```
4、当明确某个入参的参数值时，需要做参数限定，比如类似于枚举类型的参数
```go
type AA struct {
   Type      string   `json:"Type" binding:"required,eq=Type_A|eq=Type_B|eq=Type_C"`
}
```
5、代码中不要出现魔法值，需要定义常量使用
6、json.Unmarshal([]byte(str)时，如果str为空串，会报错，需要做前提判断

### sql注入的问题
1、很多时候我们直接通过变量参数拼接sql，然后执行sql，会导致有sql注入的风险
```go
	db = db.Order(fmt.Sprintf("%s %s", orderColumn, orderDirection))  // 这里直接拼接sql，根据某字段 某排序


	// 使用到的框架依赖
    "gorm.io/gorm"
    "gorm.io/gorm/clause"
	
	// 应该改成orm的方式，交给框架处理
    db = db.Order(clause.OrderByColumn{Column: clause.Column{Name: orderColumn}, Desc: orderDirection})
```

2、与用户交互的页面数据，也需要做check操作，避免类似于页面注入的行为（导致服务异常）

### 重复查询带来的性能问题，其实我们期望多请求到来时，对于相同的key查询一次就好（使用相同的结果）
https://pkg.go.dev/golang.org/x/sync@v0.16.0/singleflight
场景：
同一个策略的大量告警，查询tag信息，其实这些告警查询一次tag就可以够其使用了，不需要每次来都去查询 ，可以使用singleflight解决

### 在服务直接调用时，可以新增一个filter来管理reset重试操作
当服务A调用服务B发送reset错误时，需要尝试重试； 在filter级别做
```text
1、判断是否是reset异常；判断错误信息中是否有 "connection reset by peer" 信息
2、重试次数
3、重试间隔时间 200 - 300 毫秒
```

### 通过chan实现goroutine之间的通信，避免并发修改问题
```go
// 定时器触发，进行聚合操作
if len(bufferBlock) != 0 {
    select {
    case s.asyncUpdatingLimitChan <- struct{}{}:  // 能往s.asyncUpdatingLimitChan 中写数据，就能异步执行
        newBufferBlock := make(map[int64]struct{})
        for k, v := range bufferBlock {
            newBufferBlock[k] = v
        }
        log.InfoContextf(ctx, "defaultPolicyBinding-ticker newBufferBlock=%v", newBufferBlock)
		
		// 异步执行
        go func() {
            // 线程处理完成的标志
            defer func() {
                <-s.asyncUpdatingLimitChan
            }()
            s.handleGroupIdList(ctx, newBufferBlock) // 这里需要拷贝一份数据，不然就并发闭包问题
        }()
        bufferBlock = make(map[int64]struct{}) // 清空map
    default:
        defaultPolicyTimerTaskCounter.WithLabelValues().Inc()
    }
```

### err的判断，通过Errors.is 
1、错误判断通过内部的errors工具判断
2、https://pkg.go.dev/net#SplitHostPort 分割ip port时，通过net中的SplitHostPort工具
3、

### 告警收敛
就像prometheus中提到的告警收敛一样，主要就是解决告警风暴问题，告警收敛是一种更智能化处理海量告警的管理方式
可以将告警根据自身的维度信息进行合并，然后只向用户发送一条合并后的告警即可；比如：将多条告警信息收敛成一条告警

收敛信息：
在处理告警收敛时，尽可能的记录更多的收敛信息。比如收敛时间、收敛id、收敛状态等等，方便问题时排查定位
```text
1、一个策略可能配置多个指标、多个事件、多个实例；然后他们就会组合多种情况(在条件是任意的时候)；
    触发告警:比如 多个告警对象的某一个指标都满足时，会收到多条告警
                一个对象的多个指标满足时，也会收到多条告警    --- 带来告警风暴问题
                多个告警对象的相同事件同时触发
2、将这些告警按照一定的时间返回进行收敛，比如30分钟、一个小时发送一次
   如何收敛呢？
      在30分钟内，将该策略触发的告警都缓存起来，然后拼接触发指标、拼接触发告警对象；最后统一发送给用户，避免告警风暴
```
目前存在的局限问题：
```text
1、只能对单策略做告警收敛，多策略收敛，比较复杂，同时通知用户时与现有设计冲突
2、启动告警收敛会导致告警延时
     启动告警收敛时，我们就认为这策略存在告警风暴，需要最告警进行收敛，按照用户配置的收敛时间，然后通知用户 -- 告警延时
     但是真实的情况是，该策略可能没有告警风暴，就存在正常的告警，这样就会有一个问题，该策略的告警没有延时了
  如何解决告警延时问题了：
        ①、明确的告知配置了告警收敛存在告警延时的风险
        ②、内部在启动告警收敛时，默认会晚一分钟生效，这样这一分钟内的告警能正常告警
        ③、理想的，其实是需要一个动态检查的告警风暴的能力，比如在xxx情况下告警数量满足多少，认为需要进行告警收敛
        ④、可以看看prometheus如何实现告警收敛的 --- 重要
```


### 监听cmdb的数据信息，实现业务功能
使用场景：
基于监听cmdb的数据变化来实现业务功能，但是直接在监听到cmdb的数据变化后处理业务可能存在以下问题
 - cmdb一次性增量变化的数据太多，业务处理不及时，导致接口超时
 - 首次接受cmdb的全量数据，业务处理不及时，导致接口超时
 - 业务本身处理有效率问题，导致接口超时
上面的问题都会导致cmdb推送过来的接口超时，从而失败；导致重推

解决上面的问题：
```text
接上面的步骤拆分：
1、接受cmdb的数据，并写入mq，然后就返回。比如kafka；不做其他的额外操作 -- 特点：持久化了数据、响应速度快
2、内部背景任务，消费kafka数据，并做业务逻辑； 这些需要根据数据特点，和业务特征 判断是否相同分区是否同步或者异步执行
3、配置监控信息，监控接受cmdb的数量情况，主要包含接受的数据类型(哪个产品的)、数据量
              背景任务的消费情况，包含处理kafka的数据的延时时间、kafka主题、kafka分区、特性数据(属于哪个用户的)
              kafka实例的监控，比如kafka的主题的消费速度、数据量等等
```

编码package格式： --- 重要的
```text
srvimpl/cmdb: 这里存放cmdb相关rpc service的具体实现，内部逻辑就是投递mq
internal/unbind: 这里存放解绑相关的逻辑实现，实际上就是mq的消费要执行的逻辑
pkg/mq: 可以针对mq消费做一些简单的封装，其实主要就是方便做一些统一的监控、异常处理。
        例如提供一个 producer 实现给 srvimpl/cmdb 用，
        提供一个 consumer 实现来对接mq消费 （internal/unbind的处理逻辑可以是一个回调函数注册进去
```


### errgroup的使用方式和场景
errgroup基于组的方式异步执行任务，errgroup.wait()拿到的err就是多个任务第一个返回的err

使用方式：
1、以组的方式执行，如果有err的时候就返回err，这里errgroup.wait()虽然可以拿到第一个返回的err；但是还是需要等待所有的人执行完
2、以组的方式执行，但是当其中一个出现err时，其他任务需要被中断,基于context的cancel  --推荐使用这种，带有context取消的

### 旧服务与新服务直接的切量
需要提供一些切量标准，比如基于用户维度切量、基于使用产品维度切量（跨用户的，即所有用户）
甚至还需要同时支持黑白名单
```text
切量指定产品，但是指定用户的该指定产品不切量  -- 黑白名单的使用
```

### 模块的划分
一般建议是按业务功能内聚来划分模块， 而不是按照实现细节来划分。

### 告警的维度
在告警中，产品的告警维度用于策略的实例绑定；告警侧对产品的上报的数据十分的宽泛，且各个产品的告警维度又不一样
这样导致的一个结果是什么呢？ 在哪里中处理告警维度的时候，只能通过map[string]interface{}的方式来处理维度

这样就会导致存在很多意想不到的事，比如出现一个维度是不同产品有的是int有的是string，主要是在解析上面可能会存在问题
```text
比如：将number类型的使用科学计数法表现了处理，这样就会埋下问题
```

处理方式，是否可能定义元数据的方式，让产品上报数据
```text
attrName: instanceId
attrType: string
attrValue: xxxxx

attrName: appId
attrType: int
attrValue: 123456
```

然后专门提供一个服务，用于处理这种数据结构的解析，只要是从这个服务提供的解析方法算出来的维度，那么就是符合告警的维度，告警内部的所有其他的服务，都可以复用

### 基于k8s，如何进行多pod节点的选主
statefulSet场景：
```text
statefulSet 本身就是k8s提供的有序的pod；每个pod都有自己的编号，即使这个pod被销毁重建了，也不会改变其pod的编号信息

所以我们可以基于statefulSet的特性，让变化为0的pod，成为服务集群的master，其他的pod成为slave
```

Deployment场景：
````text
Deployment 是无序的，内部也没有什么标记，pod被重启就是一个全新的服务了

在tag-bind场景，通过mysql的表记录来确认哪一个是master
过程如下
前提：
pod1  number1 pod1基础信息
pod2  number2 pod2基础信息
pod3  number3 pod3基础信息

初始化检索pod，pod1，pod2，pod3一次启动
此时pod1先启动，先向mysql表中插入自身信息记录，并占用该行 --- 表示自己抢到资源成为了master
pod2、pod3启动，向mysql表中插入自身信息，发现键值冲突，于是成为了salve

pod重建场景
此时pod1，因为异常原因被销毁重建了，在重建的时候的hook操作中，删除了mysql表中的记录，现在成为无主情况
pod2，pod3，new_pod 抢占资源，谁抢到了谁就是master


在代码层面就是：
三个pod都会加载mysql表中的数据(其实就是master pod的信息)，通过加载到的pod信息和自身信息比较，如果自己是master，那么就干master的事情，否则就干salve的事情


````
### gorm sql操作没有就新建，存在就更新
[How to Create or Update a record with GORM?](https://stackoverflow.com/questions/39333102/how-to-create-or-update-a-record-with-gorm/54251638#54251638)
```go
// Update columns to new value on `id` conflict
DB.Clauses(clause.OnConflict{
  Columns:   []clause.Column{{Name: "id"}}, // key colume
  DoUpdates: clause.AssignmentColumns([]string{"name", "age"}), // column needed to be updated
}).Create(&users)
// MERGE INTO "users" USING *** WHEN NOT MATCHED THEN INSERT *** WHEN MATCHED THEN UPDATE SET "name"="excluded"."name"; SQL Server
// INSERT INTO "users" *** ON CONFLICT ("id") DO UPDATE SET "name"="excluded"."name", "age"="excluded"."age"; PostgreSQL
// INSERT INTO `users` *** ON DUPLICATE KEY UPDATE `name`=VALUES(name),`age=VALUES(age); MySQL

```

### kafka相关的
```go
在原有的实现中，如果Kafka ConsumerGroup 在连接Broker时出现异常不会重试且该信息未能返回给 ConsumerManager。
考虑到 Sarama 库的设计特性，全均衡也是需要重新执行 Consume ，即 Consume 应该在一个无限循环中执行。

所以这里对于连接异常的情况，会通过状态方法对外返回，由 Manager 对此进行移除，并在后续触发重新Start（重连）。
```

### es查询时忽略不存在index的错误
构建es查询的url时，拼接一个ignore_unavailable=true的参数
```text
    // 忽略不存在的索引
    URI: fmt.Sprintf("/%s/_search?ignore_unavailable=true", indexStr),

```

### 开发中注意的编程问题
1、设计sql时，需要对字段的类型与长度做出合理的判断
2、mysql的utf8，有坑；应该使用CHARSET=utf8mb4
3、gorm中的find不会返回gorm.ErrRecordNotFound，first才会返回
4、sql语句如果有多表联查的时候，需要走索引，避免效率低下问题
5、sync.Map 适合读多写少的情况，如果只是写写冲突，可以考虑使用map+sync.mutex
6、for-range 遍历切片时，如果切片len=0，就不会进入for-range；所以不需要判断len==0
7、返回错误时，如果一个方法中多处返回err，需要通过fmt.Errorf()携带更多的信息，方便错误时排查问题
8、gorm中查询数据时，指针和对象都可以查询出数据，但是最好是对象，而不是指针
```text
什么时候使用指针，什么时候使用对象呢？

一般自定义的service使用指针
需要变化的数据对象使用指针
不需要改变的使用对象
```
9、在处理一些业务数据时，这些数据需要从db读取，变化小，量级小，使用场景多；可以通过背景任务定时加载到内存中使用
10、sync.RWMutex成为成员属性时，会影响数据的复制？？？
11、限制并发度的方式
```golang
limit <-struct{}{}
sg.Go(func() error  {
    defer func(){
        <-limiter
    }()
   // 业务逻辑
    return nil
}
```
12、golang中的类型零值，不需要单独赋值
13、最小访问权限原则，避免变量作用域放大
14、多使用标注库的常量信息，比如时间相关的




