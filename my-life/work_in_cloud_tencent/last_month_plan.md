
## last month plan



目的是：
1、了解今年来的功能
2、通过mr查看一些golang的编码规范、设计模式 --- 这个真的很重要



中间件在监控使用的场景:  
```text
mysql
    正常的数据存储
    
redis
   在amp和adp场景都有使用，但主要的功能还是用于作缓存，比如告警对象的缓存、告警历史的缓存、通知信息的缓存
   
kafka
   事件   
   默认策略  用于异步削峰解耦，基于hash key 分区处理，但存在某个产品数量大，且不关心的场景，导致下游数据消费慢，导致的效率问题 -- 解决方案 拆分更细粒度的分区
   adp  聚合的指标信息，用于告警检测

elasticsearch
   告警历史
...
```


监控的架构，从数据接入到监控告警通知用户
```text
1、前提接入配置
  哪个产品，需要接入哪些指标维度、计算维度(比如1分钟、5分钟、15分钟、1小时等等)、事件类型

  计算维度在在指标维度的基础之上拓展的，主要是方便用户告警配置使用
  
2、产品侧主动上报数据
产品侧 -> 网关（丰富产品信息）-> kafka(源数据) -> flink (定时拉取接入配置，生产任务，实时计算) -> kafka(计算后的数据，比如1分钟、5分钟、30分钟聚合后的数据) -> 存储层(将数据存放到es、xstorm中，提供接口查询或者用于离线任务) 

同时kafka(计算后的数据，比如1分钟、5分钟、30分钟聚合后的数据) -> 告警使用 (用于检查是否告警)

产品侧  ----提供产品丰富信息

3、维度数据上报
在告警时，用户其实希望拿到更多的监控对象的一些信息、甚至是实例的标签信息
于是就引入了监控侧的cmdb(configuration management database) 用于存放各个云产品的核心数据信息，这些信息主要用于和告警的联动
使用场景：
  - 告警丰富信息 现在的告警丰富是通过php脚本执行，动态调用产品侧的接口实现获取的信息， 但是这里有很多问题，比如：php脚本难以维护、没有提供自测能力(只有等到告警失败的时候，才知道php脚本写错了)、新增信息比较困难（改脚本、产品改接口、无法自测）
  - 新增告警指标 在现有的情况下，我们是在接入的时候就已经定义好产品的namespace、视图名称、namespace-viewName下的指标信息，计算侧会基于接入的这些配置，生成flink任务计算；如果要新增由于历史原因，我们不能在原来的视图上面做新增，只能新增视图
               新增视图带来的缺点就是，存在重复的指标，而在监控侧这些指标计算又是直接存放到内存中的， 这样会导致内存增加，成本也会增加；成本增加后就需要后产品侧均摊，这是大家都不愿意看到的事情
               而引入维度服务后，产品侧想新增告警指标，就可以将数据上报到监控侧的cmdb中，监控侧就可以拿到这些数据做新增指标
  - 解决数据存储多份的问题 因为在监控侧存在很多的业务都需要使用到产品的信息，比如监控告警、AI工作台、计算层等等，之前大家都各自为政，当需要产品侧数据的时候，都找产品侧提供接口，拉取数据 -- 数据存储多份(存储成本)、可能内部命名规则还不一致，这样会导致内部协同时发现
               明明就是一个东西，但是命名千奇百怪的，对维护者很不友好、产品侧和监控侧维护多个接口

```

监控页面的功能、产品的信息




监控的核心业务梳理，自己负责的核心业务

告警指标上报： 告警网关
告警指标聚合： 告警计算，各个云产品的指标聚合 sum max min count  60s 300s 15min 1h 1d
告警存储： 消费kafka中的数据，并写入es、xstore 供页面查看，或者告警检查的环比、同比
告警检测： 消费kafka中的数据(指标数据)，根据信息找到匹配的策略(filter匹配，主要是哪个实例)
```json
[
  {"Function":"Equal","Field":"appid","Args":"1251763868"},
  {"Function":"Equal","Field":"projectid","Args":"0"},
  {"Function":"Equal","Field":"vm_uuid","Args":"ba53fdd0-7222-441e-8a71-9cdd031c0bbf"}
]
```
匹对方式：
如果是equal和in方式的话，可以将穷举出来，将每个都做成taghash，快速匹配   ---但是大部分都是这个，提升效率
其他的就只有内存多条件判断了

将数据库中的数据全量加载到内存中（分区分表 -- 如果是大地域，那么还会根据该地域下的产品分）主要有以下目的
1、当存在机器故障或者其他的问题时，控制影响范围
2、大地域的策略、规则、filter比较多，全量加载到内存中，会对检查效率有压力，将其分散处理
3、减少产品之间相互影响的概率
4、。。

告警通知： 基于告警检测过来的通知，匹配对应的用户发送告警通知
pipeline流程： 告警限制、通知频率（没有到达通知点，不发送通知，直接返回）、告警屏蔽、告警收敛、告警丰富、告警通知(短信、邮件、电话、webhook、机器人)、通知历史、告警历史 等等
引入了多个概念：
1、通知方式 channel
2、订阅关系 用户、用户组、值班表与通知方式的关系
3、消息体
4、来源，通知行为的来源
5、通知模版
6、告警历史

存在的问题：
1、并发度不高，主要以pipeline 一个协程执行到死
2、无执行顺序控制，可能存在乱序问题  --- 虽然控制了指定的来源方的顺序执行(底层还是线程池执行，只是控制了并发度，减少了完全没有控制的场景)
3、内部存在大量的定制适配功能
4、服务功能不单一，总是干了一些不属于该服务的事情，比如：操作告警历史直连es
5、日志输出，对于一些退出条件(不同的状态退出链路)，没有很好的通过log key的方式统一收敛到一个status中，导致工单排查判断比较困难
6、...

日志业务层面的改善： 定义一些业务语义
```text
1、主调信息(主调服务、主调方法、主调地址ip)，被调信息(被调服务、被调方法、被调地址ip)，地域信息、set信息
2、告警状态(触发、恢复、收敛、屏蔽、频率限制、各种失败状态)、通知id、屏蔽id、用户id、策略信息、维度信息、告警id、上下文信息(比如:核心业务关联的)
3、细化通知相关的，比如通知方式、来源、消息、通知模版、订阅关系等
```


prometheus 的使用promql还得补一补:




ai工作台： mcp eino rag agent mcp: go-mcp 框架

知识库：
1、接受cmdb的数据，并将其信息写入到es(作为向量数据库)中，方便根据关键字召回
2、提供查询服务: 支持搜索告警策略、告警指标、API指标、云产品(指标、事件、文档等)的元数据信息 
```text
具体逻辑：
根据入参，从向量数据库中召回数据(如果这里召回失败，向量查询退化成关键字查询)，然后再通过召回的数据到es(es支持向量查询)中查询

疑问:
1、何时向向量数据库中存放关于监控侧的信息呢？ 向量数据库如何实时更新最新的监控语义信息呢
2、从es向量查询的数据，这些数据是通过cmdb写入的吗？
    分两种： ①、文档(元数据，控制面数据，比如：策略元数据，指标元数据(接入层面定义的元数据))    --- 不同的es index
            ②、接收cmdb的增量通知，写入到es中  --细节：如何避免数据的覆盖(版本号)、标记来源方、标记地域、标记是否被删除等等  --- 不同的es index
```
3、



分布式:

微服务系统： 服务注册、发现, 服务寻址(set路由、就近路由、meta路由)、负载均衡(随机、轮询、加权轮询、..)、服务熔断(服务降级、服务恢复)


### 关注哪些可观测的指标
请求错误量、请求响应时间、请求成功量
```text
通用层面基于类AOP实现(filter)
 业务状态码     code 比如：500 200 401 等等  这里可以统计出：请求错误量，请求成功量
 请求响应时间   业务处理请求的响应时间
 
 主调、被调等信息

业务层：
  amp：告警请求总量 counter label有(产品标识，告警标识，地域，处理结果)
  amp: web_hook_req counter   label有(请求地址、响应状态)   -- 用于记录总数
  amp: web_hook_used gauge    label有(请求地址、响应状态)   -- 用于记录请求花费时间
  
  default_binding: 对于一些比较重要的操作，既可以记录接收时的量和成功处理的量，比如cvm的异步绑定  -- counter
  
  mq 的延时消费时间、mq的数据的处理时间 -- 使用 histogram (柱状图)  单位秒在指标名称中体现
  mq 的消费者消费的数量总和 --  counter
  
  
```
📢：(重点)
一个系统中，如果对数据敏感，且需要保证实时性的时候，需要对核心依赖的中间件做指标上报处理（特别是异步处理的时候，连接失败也不会影响整体流程，但会导致实时性问题的场景）
```text
比如：
  连接失败次数的上报  -- 告警通知，人工介入
```

有时候在做一些功能升级，或者依赖的中间件切换的时候，会提前埋点一些指标(比如counter类型的指标)，方便系统切换放量后，做对比
```text

```

在业务降级处理的地方，为了能更好的观测到，可以设置观测指标，如果只打印日志的话，大多时候日志都会被忽略掉  -- 当量级比较大的时候，非关键的日志就会容易被忽略

在业务中，数据流转过程中，可能存在数据缺失的情况，但是这个情况又是那种终止流程不合理的情况，所以需要添加一些指标来关注，后续方便优化

在业务中，经常会使用到线程池的场景，内部使用ants.pool,外部在自己包装一层，并提供可观测的手段(定时上报)，关注的指标有：运行中的协程，空闲的协程、协程总数、队列总大小、使用中的大小、队列剩余大小

在业务中，对于一下异步读写，并阻塞的场景，可以通过counter记录，运行期间是否存在大量的阻塞情况，如果有，就需要排查是否是生产过快，还是下游消费慢，还是chan的大小设置不合理

重要的外部系统调用失败的counter

总结一些，上报指标的特性  --- 注意一定要避免大基数的label指标
```text
类型的话：
counter   类  -- 请求量、成功量、失败量、根据响应结果信息记录的数量、某种状态的数量，比如告警中的各种状态数据(触发、恢复、告警丰富失败、屏蔽、收敛。。)
gauge     类  -- 内部的线程池中的协程使用率，队列使用率、也可以用于处理记录请求的花费时间、也可以记录mq的消息的处理时间，以及延时时间 、异步任务中的goroutine数量统计
histogram 类  -- 业务处理时间范围、mq延时时间处理范围、主要还是时间的花费：内部任务的执行时间范围、查询呀、数据构造呀等等花费的时间
```

### 各个服务的qps

业务服务
 amp 800多的qps
 adp 6000多的qps
 policy  50多的qps

中间件
redis
 连接的数量在1w个左右
 总的qps: 551670    读请求: 305844   写请求: 236873

mysql

### 服务pod量

adp
广州地域 200+个pod； 大概有接近60个地域， 总pod数2000+ pod数

上海 150+ pod



amp:
20+pod

policy：
7 个pod



