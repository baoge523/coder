

### sync.Pool
减缓gc、用于对象复用
```text
1、用于对象复用，主要针对于生命周期长的且无状态的对象，短生命周期的对象不建议使用sync.Pool
2、最佳实践参考：fmt中的pp使用sync.Pool达到复用pp对象
3、通过sync.Pool的Get方法的描述信息可知：Get获取到的对象，可能是pool中的对象也可能是New出来的对象；put和get的对象不能有依赖(无状态对象)
    - 但可以在每次new出来之后往对象中设置基础值(大家共用的)
```

### zap 需要了解一下，rpc-go的log就是包装的zap logger --- 需要找一个样例
https://pkg.go.dev/go.uber.org/zap#pkg-functions

一个强大的日志输出框架，very fast

提供了两种日志对象：logger 和 SugaredLogger ；
```text
logger : faster、strongly typed(强类型) and inexpensive
SugaredLogger: 相对于logger会慢一些、loosely typed(弱类型)、simple
```

zap创建logger对象的方式：
```text
Simple: 直接通过内置的方法创建，简单只适用于测试，单测，demo应用
Basic config:  基于config创建
Advance config:  基于config创建
```

Log:
```text
流程: 写入 -> 序列化 -> 输出
在序列化可以动态改变或者自定义: 比如 json,fmt等等
输出(sink):  控制台、file、kafka、other 等等
```


### uuid 生成
github.com/google/uuid 生成uuid
```go
import (
"fmt"
"github.com/google/uuid"
"testing"
)

func TestUuid(t *testing.T) {
    newUUID, err := uuid.NewUUID()
    if err != nil {
		fmt.Println(err)
        return
    }
    fmt.Println(newUUID.String())
}
```

### K8s中服务的销毁重建，镜像版本升级是怎么停止程序的
当k8s中的pod销毁重建时(重建pod、镜像升级、版本回退等等)，pod会向里面的所有容器发送unix.sigTerminal指令，用户的应用程序应该需要监听该指令进行应用程序的优雅退出

在golang中、如果程序有内存级别的channel消费，那么这个channel里面的数据会丢失吗？
> 如果业务没有实现goroutine的安全退出，那么就会丢失数据


### rpc中如何进行优雅退出的？
这里需要弄清楚在程序退出时，哪些资源需要退出，比如在rpc中有：server、service(rpc\http),net.listener、net.conn等等

关系信息：
```text
server 下有 多个service；每个service都会监听一个端口(net.listener)

监听的端口(net.listener),有链接建立的时候，就会新建一个net.conn (当然如果是相同的src可以复用tcp连接)

net.conn 有空闲时间、keepalive、等参数 -- 底层都会复用连接的，毕竟创建连接的成本还是挺大的
```

所以在rpc监听到容器的sigTerminal指令后，需要关闭这些对象
①、执行server的退出函数
②、依次执行service的关闭函数  --- 有超时限制
   关闭service函数做了哪些事情呢？
```text
1、关闭net.listener ，不再接受请求
2、执行context的cancel，关闭所有的连接对象 -- 父context执行了cancel，其所有的子context都会接收到cancel信号
3、这里有一个疑惑，具体的执行业务操作的context不是service的context派生出来的，所以在退出时没有优雅的退出；但因为主线程退出来，这些子线程也会退出
```
③、main函数执行完毕，执行用户应用的defer函数
```text
应用级的defer函数就是用来优雅退出应用的
比如：
 - 不再生产数据(不向内部chan写数据)
 - 关闭内部的chan、但需要等待消费chan的协程处理完毕，通过sync.WaitGroup{}、errgroup 的 wg.wait()实现等待
 - 执行context.cancel通知内部线程
```

### rpc的service是如何监听rpc的连接的

1、底层还是使用的net.listener，但对其包装了一下；然后调用包装的l.accept(),但是底层还是使用的net.listener.accept()

2、监听到请求：请求本质是一个io.reader对象，然后rpc封装的codec会从请求(io.reader)对象中读取字节数组-数据
> ①、读取rpc-header信息，校验里面的魔数、header中有四个字节(32位)用来表示rpc-body的大小，同时也会校验这个body的大小，不能太小和不能超过10m
>
> ②、读取rpc-body信息，通过header中的body长度从io.reader中获取

3、通过service的hander来处理rpc-body信息 — 这里想想也是合理的，只有service才保存了自己所有的handler处理，才可以匹配到这次请求到底请求的是哪一个rpc接口
> ①、通过codec得到msg和context对象
> 
> ②、通过codec将request请求信息封装到msg中；caller的元数据信息，比如超时时间
```text
- 超时时间：service的超时时间、对应rpc接口的超时时间、caller的超时时间，三者取最小；context.WithTimeout(ctx, timeout) 创建出带有超时时间的ctx
- 构造filter-chain；在构造filter-chain的func时，会对应请求体做解压、反序列化操作拿到最终中的body；
1. **压缩**：减少数据大小，提高传输效率，降低带宽消耗，缩短传输时间。
2. **序列化**：将数据结构转换为可传输的格式，使其能够在不同系统之间传输和重建，确保数据完整性和一致性。
```

4、通过codec拿到的msg拿到caller的methodname，从而拿到handler； 然后执行hander


### ants.pool 线程池


### K8s中的服务注册、监听服务
个人理解： k8s在注册服务时，可以设置端口的监听协议，比如tcp、udp；同时还需要设置服务的接收请求协议，比如tcp、http；如果设置成http协议，那么只能通过http协议访问该服务，使用tcp的方式访问该服务就会报错

### K8s的网络学习
同一个node中的不同的docker 容器之间的相互通信，通过veth pair 实现，veth pair可以跨network namespace

### Go并发场景 — 控制与逻辑的分离；开发更多是关系逻辑，控制交给架构(框架、工具)  --需要补全呀 
健壮性考虑：
1、goroutine异常时，比如业务中抛出panic，goroutine 没有对panic处理会导致整个业务异常退出
2、goroutine的链路追踪问题，如何定位goroutine的执行情况
3、goroutine参数问题，比如context信息，request scope param 透传等信息

可读性问题：
我们往往写goroutine的时候会在业务中夹杂着大量的控制的代码，这样会导致控制与逻辑没有分离，从而导致阅读代码的人分不清楚逻辑信息
《《所有的软件架构、设计模式解决的根本问题在于控制和逻辑的分离。我们不希望加重开发者的负担，而是更多的聚焦在业务逻辑上》》

```text
errgroup 是golang提供的工具，可以对goroutine进行管理，
比如
 - the number limit active goroutine in a group
 - err handle
 - context.cancel 当通过带有context的方式创建errgroup，那么当第一次遇到err时，就会执行context.cancel，就可以快速失败其他的任务
 
golang.org/x/sync/errgroup
```

工作流的解决方案：
比如在一些场景下，需要解决类似于流水线一样的工作的任务，比如 执行 A, B依赖于A执行的结果，C依赖于B执行的结果 等等，这种流水线的任务
监控中有这样的场景吗？
cmdb：cmdb只是定时的拉取各个产品侧的数据，然后于数据库中的数据比较，最后将变更数据转换成列式存储

