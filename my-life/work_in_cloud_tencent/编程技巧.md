
### 一个服务是需要监听系统的signal(信号量)来做一些优雅退出操作的
1、需要判断自己使用的框架的架构中是否有监听操作系统的信号量来做优雅退出
```golang
// trpc就有做监听系统退出signal
import (
"os/signal"
"golang.org/x/sys/unix"
)

// 业务初始化操作完成，

// 注册，并监听操作系统的信号量
signal.Notify(s.signalCh, unix.SIGINT, unix.SIGTERM, unix.SIGSEGV)

// 阻塞等着在这里
select {
case <-s.closeCh:
case <-s.signalCh:
	// do something
}

// 接收到系统的退出信号量，执行优雅关闭操作

```
2、如果没有，就需要自己在服务系统中监听一下系统的退出信号量
```golang
import (
"syscall"  // unix
)

signal.Notify(signalsChannel, syscall.SIGHUP, syscall.SIGTERM)

// 监听 signalsChannel --- 可以异步监听，然后调用服务的close方法，优雅关闭服务
```

### 如何实现一个读取配置文件的框架信息
1、自定义配置的结构体
2、通过loaderFactory 创建出loader，同时指定配置的结构体(可以携带默认值，如果配置中有就覆盖默认值)
3、loader.start() --> 底层就是调用具体的配置加载器，去加载配置，同时判断是否需要动态监听配置
4、获取配置，不能直接返回配置对象；而是在需要使用配置的时候，通过func调用动态获取；运行时获取 --- 重要


```text
yaml.v3@v3.0.1

// 将u的值，Unmarshal 成 i 结构体
yaml.Unmarshal([]byte(u.Value()), i)

// 匿名函数 -- golang 中经常使用匿名函数的，需要习惯
func (i interface) error {
    return yaml.Unmarshal([]byte(u.Value()), i)
}
```
### sync.pool的使用场景
sync.pool主要是用于复用对象(复用内存)；基于复用对象的方式，减少频繁的创建对象(内存分配)；减少gc

场景：
 - 用于读取io.body中的数据的buffer(bytes.NewBuffer(make([]byte, 0, initial)))

### json工具
json解析
```text
github.com/json-iterator/go@v1.1.12
jsoniter.Unmarshal(buffer.Bytes(), &records)
```

### 业务处理数据时，数据入口处
1、数据尽可能的结构化
2、不能结构化的数据来源方需要确认原因，如果是新增的，那么就尽可能满足结构化；如果是遗留的，需要分类兼容一下
3、检查数据的合法性， -- 兼容性判断，根据不同的策略就行操作， 比如数据没有值时，是补充默认值，还是直接丢弃，还是其他的处理

### 通过工厂方法创建对应的对象时，如果对象的配置存在必填、选填等配置时，可以通过option的方式，以闭包的行为在使用时，动态的注入进去
```golang
func NewFactory(
	cfgType Type,
	config Config,
	options ...FactoryOption,
) Factory {
	f := &factory{
		cfgType:                 cfgType,
		CreateDefaultConfigFunc: createDefaultConfig,
	}
	// FactoryOption 是一个个闭包函数，里面有applyOption方法，将闭包中的数据设置到f这个配置中
	for _, opt := range options {
		opt.applyOption(f)
	}
	return f
}
```

### kafka-go的使用
```text
github.com/segmentio/kafka-go@v0.4.47

WriteMessages(ctx context.Context, msgs ...Message)
```

### 根据数据的流向，将数据处理分为：接收器、处理器、输出器
接收器: receiver 、source
处理器: processor
输出器: sink、exporter

上面的组件都有自己的生命周期管理，比如启动、销毁；所以可以定义一个公共的接口 component interface 其中定义了start stop(shutdown)接口

细节：--- 重要
```text
1、每个组件都有自己的业务逻辑处理细节，但是正常情况下避免日志爆炸，所以我们只会输出流程日志，对一些细节性的日志不太关系
2、但是当我们发现组件存在问题时，此时需要查看更多的日志细节，所以我们可以通过开启在组件中的埋点日志，比如debug、trace级别的日志


这个很重要，在日常开发中，我们只关心了正常的情况的日志，且也没有通过不同的日志级别输出日志，这样就会造成两种极端的问题（日常开发都是info级别的日志）
1、日志输出很详细，都是info级别的；当出现异常情况还好可以基于这些日志排查问题，但是正常情况(理论上99%以上的时间)日志爆炸，磁盘很多就被打满，造成其他的一些意外情况
2、没有关键日志输出，当业务发现问题时，通过日志定位问题，发现通过日志无法定位到哪个组件，或者组件内哪个部分出现了问题；于是就只能修改代码添加关键日志；费时费力，关键是有的环境不轻易让替换版本
```

管理侧的接口：修改日志级别，内部管理

可以在各个组件中定义日志级别，并可以设置日志级别，并在设置后，定时关闭(防止忘记将日志级别改回去)
```go
// Debugger debugger通用接口
type Debugger interface {
	SwitchDebug(flag bool)
	SwitchTrace(flag bool)
}

// Component 实现了Debugger接口的通用组件
type Component struct {
	cancel context.CancelFunc
	Debug  bool
	Trace  bool
}
```
Component 实现了Debugger接口，可以启动、关闭debug、trace级别的日志
所有的组件，都是组合了Component，可以实现动态开关的能力

### 文本编解码
```go
// TextMarshaler is the interface implemented by an object that can
// marshal itself into a textual form.
//
// MarshalText encodes the receiver into UTF-8-encoded text and returns the result.
type TextMarshaler interface {
	MarshalText() (text []byte, err error)
}

// TextUnmarshaler is the interface implemented by an object that can
// unmarshal a textual representation of itself.
//
// UnmarshalText must be able to decode the form generated by MarshalText.
// UnmarshalText must copy the text if it wishes to retain the text
// after returning.
type TextUnmarshaler interface {
	UnmarshalText(text []byte) error
}
```

### 数据的传输，需要考虑压缩和序列化
压缩：减少数据大小，提高传输效率，降低带宽消耗，缩短传输时间  -- Gzip，LZ4，Zstandard (Zstd)
序列化: 将数据结构转换成可传输的数据格式，使其能够在不同的系统直接传输和重建；保证数据的完整性和一致性 -- proto，json

场景：
1、网络传输，比如rpc的数据传输中，可以先使用序列化，然后再压缩
2、内部数据流转场景，比如producer\consumer模式的数据传输，可以只使用序列化

序列化操作
```go
// proto序列化
"google.golang.org/protobuf/proto"
proto.Marshal(&pb.MetricList{
		Namespace: ns,
		Metrics:   metrics,
	})

// json 序列化
"encoding/json"
json.Marshal(&pb.MetricList{
    Namespace: ns,
    Metrics:   metrics,
})

```

### prometheus 的使用
一般常见的监控的是：
 - gauge   仪表盘
 - counter  数量值
 - histogram  柱状图

gauge
```go
// 声明
	gauge := prometheus.NewGaugeVec(prometheus.GaugeOpts{
		Namespace:   namespace, // full name = namespace_subsystem_name
		Name:        name,
		ConstLabels: map[string]string{}, // 常量labels信息，比如 "code":200,所有的都默认加上，根据场景指定常量labels
	}, labels) // labels 监控的维度
	
	// 注册指标到prom中
	prometheus.MustRegister(gauge)
	
// 使用
gauge.WithLabelValues(labels...).Set(v)
```
counter
```go
// 声明
	counter := prometheus.NewCounterVec(prometheus.CounterOpts{
		Namespace:   namespace,
		Name:        name,
		ConstLabels: map[string]string{},
	}, labels)  // 这里的labels是key
	prometheus.MustRegister(counter)
	
// 使用
counter.WithLabelValues(labels...).Add(float64(v))  // 这里的labels是value，与定义的时候对应
counter.WithLabelValues(labels...).Inc()            // 这里的labels是value，与定义的时候对应
	
```
histogram
```go
// 声明
    histogram := prometheus.NewHistogramVec(prometheus.HistogramOpts{
        Namespace:   namespace,
        Name:        name,
        ConstLabels: map[string]string{},
        Buckets:     buckets,
	}, labels)
    prometheus.MustRegister(histogram)
	
// 使用
histogram.WithLabelValues(labels...).Observe(v)
```

### go gin middleware


### options 模式开发，一般用于可选的配置项操作
1、定义个配置struct，该struct里面包含多个配置项
2、定义一个option方法，该方法的入参就是定义的配置struct
3、提供入参是配置项，且出参是option方法的func，这些func用于动态调用时，向配置struct设置配置项
4、定义一个执行func，该func用于将配置项设置到配置struct中 -- 这个可以根据情况而定

具体实现如下:
```go
// NewOptions 新建统计对象时候的参数
type NewOptions struct {
	Description string         // 配置项1
	Buckets     []float64      // 配置项2
	Policy      GaugeAggPolicy // 配置项3
}

// Apply 执行修改函数；执行配置项func，将设置配置
func (o *NewOptions) Apply(f ...NewOption) {
	for _, currFun := range f {
		currFun(o)
	}
}

// NewOption 设置参数
type NewOption func(*NewOptions)

func WithDescription(d string) NewOption {
	return func(no *NewOptions) {
		no.Description = d
	}
}

func WithBuckets(b []float64) NewOption {
	return func(no *NewOptions) {
		no.Buckets = b
	}
}

func WithAggPolicy(p GaugeAggPolicy) NewOption {
	return func(no *NewOptions) {
		no.Policy = p
	}
}

```

### 可观测： 指标、日志(不同级别的日志)
在应用开发中，正常的思维时，只关系自己的业务功能代码，这样程序是可以正常跑起来，但是我们无法看到程序的内部运行情况，
只能通过一些linux的性能查询工具来判断应用是否正常，比如通过ps,netstat,pid,top,
或者一些语言体统的性能查询工具，比如gops,pprof等等，但这些工具查询的又是和业务无关信息的

总之: 没有可观测的应用系统，就相当于在裸奔

监控指标统计方式：
  - count  总数 只增不减
  - gauge  仪表盘  可增可减
  - histogram 柱状图 

监控指标，可以参考golang中的实现库otel
```text
指标定义：https://pkg.go.dev/go.opentelemetry.io/otel/attribute
opentelemetry语义: https://pkg.go.dev/go.opentelemetry.io/otel@v1.37.0/semconv/v1.11.0
```

应用场景:
```text
请求成功数量
请求失败数量
连接失败数量
响应时间柱状图
```

业务场景：
> 市面上可选的监控系统比如多，为了提供系统的健壮性，将系统可能用到的监控统计方式抽离成接口的方式，与底层真正的业务实现分离；以达到面向接口编程、动态可插拔效果
> 比如底层正在实现是：prometheus、获取内部一些监控系统

实现统一的内部实现器，屏蔽外部具体实现(外部实现供使用者使用时提供)
```text
1、提供通用的接口定义 -- 这个需要考虑到常用惯例
2、提供对外创建指标统计的接口和provider的接口定义
3、提供provider的默认实现和外部注入provider的方式
4、提供通用接口的默认实现，比如delegation\noon实现

5、用户测：提供provider的实现，并注入到框架中，然后使用暴露的接口
```

### 日志: zap日志的使用
```text
 https://pkg.go.dev/go.uber.org/zap#pkg-functions
   一个强大的日志输出框架，very fast
   提供了两种日志对象：logger 和 SugaredLogger ； 
       logger : faster、strongly typed and inexpensive
       SugaredLogger: 相对于logger会慢一些、loosely typed、simple
  zap创建logger对象的方式：
      Simple: 直接通过内置的方法创建，简单只适用于测试，单测，demo应用
      Basic config:  基于config创建
      Advance config:  基于config创建
   Log:
    流程: 写入 -> 序列化 -> 输出
    在序列化可以动态改变或者自定义: 比如 json,fmt等等 
    输出(sink):  控制台、file、kafka、other 等等
```
go配置：
```go
var DefaultConfig = zap.Config{
	Encoding:    "json",
	Level:       zap.NewAtomicLevelAt(zapcore.DebugLevel), // 输出级别
	OutputPaths: []string{"stdout"},                       // 输出目的地
	EncoderConfig: zapcore.EncoderConfig{
		MessageKey:   "message",
		LevelKey:     "level",
		CallerKey:    "Caller",
		FunctionKey:  "Func",
		EncodeLevel:  zapcore.CapitalLevelEncoder,
		TimeKey:      "time",
		EncodeTime:   zapcore.TimeEncoderOfLayout("2006.01.02 15:04:05"),
		EncodeCaller: zapcore.ShortCallerEncoder,
		LineEnding:   zapcore.DefaultLineEnding,
	},
	InitialFields: map[string]interface{}{"logger": "default"},
}
```

### 应用业务请求的超时控制
日常的业务场景都是request-response，我们可以通过控制业务的超时请求，来达到控制业务的场景，防止其他意外情况方式，保证服务的稳定性

一般超时控制的设置方式有如下：
 - 整体服务的超时设置，表示该服务下所有的请求的超时时间
 - 服务侧，配置指定的功能的超时
 - 客户端侧，调用请求时，指定超时

通常情况下，会三者取最小的，才是超时时间； 这样可以在超时时，快速失败，避免资源的浪费

```go
// 在golang中，可以通过context.cancel来实现超时控制
context.ContextWithCancel(...)
```

### 组合模型：内嵌接口 vs 接口func type
优质的代码是将控制与逻辑分离，暴露简单的用户访问入口，即可快速实现初始化或者注册
```text
正常情况下，面向接口编程，定义接口，然后让用户使用侧实现这些接口就好了，然后面向接口使用这些接口中定义的方法就好了

常见的开发模式是： map + interface   该方式可以在运行中动态切换，通过key找到map中的interface实现者，使用ta

提供可切换的行为，但是在系统初始化的时候，只会选择一个，不会在运行中进行切换
   delegation + defaultImpl + register + interface   需要用户使用时通过interface的真实实现，然后通过register注册，替换delegation中的defaultImpl
  
```

#### 内嵌接口 - 委派器模式
通过自定义一个委派器的type，内嵌目标接口，即在使用委派器时，需要用户传入该接口的具体实现；然后就可以使用该package提供的便捷方法

  - 参考指标统计、日志的实现即可

#### 接口func type
通过将接口定义的func，重新定义成type，然后将其作为初始化参数，进行初始化对应的实例

定义侧
```go
type A interface{
	Eat(string) error
}
// 定义一个func type 用于表示 interface a 中的eat
type WeEat func(string) error

func NewA(eat WeEat) A {
	return &defaultA{Eat: eat}
}

type defaultA struct{
	Eat WeEat
}
func (a *A) Eat(something string) error {
	return a.Eat()
}

```

// 用户侧 （初始化侧）
```go

// 简简单单就把对象构建好了，比如用户实现接口的方式方便多了
func FishNewA() A {
	return NewA(EatFish)
}

func EatFish(something string) error {
	fmt.println("we like eating fish and something")
	return nil
}
```

// 进阶 都可以在多个map 指定key的方式管理


### 复杂系统设计  --- 编码验证一下，简单的就可以，主要验证流程
可以通过数据的流向将数据处理分为如下三个阶段：

 - 接收器 
 - 处理器
 - 导出器

```text
接收器：
  获取数据的方式：
    push 数据源方，将数据push过来，比如prometheus的remote write、提供http、rpc接口
    pull 我方将数据pull过来，比如，调用数据源方的接口，消费kafka数据
    
   拿到这些数据后统一做处理(数据加工)，如果只是报错源数据信息，那么就直接存储不加工
   
   通过next consumer（这里是一个抽象概念的consumer），可以是写入到db、kafka等

处理器：
    比如批量处理、数据协议转换处理、数据前置处理、数据后置处理
    
    本质就是可定制化加工数据

导出器：(一般作为接收器的下游，或者处理器的下游)
    消费数据，将数据持久化存储：比如消费数据，然后写入es、kafka等




常见模式：pipeline 模式
pipeline1: 接收器 -> 处理器 -> 导出器
pipeline2: 接收器 -> 导出器
pipeline3（内部中间操作）: 处理器 -> 导出器

pipeline4: 接收器 -> 处理器 -> *** -> 处理器 -> 导出器   接口设计得很通用的话，就能达到这种效果

pipeline5: 接收器 -> 处理器 -> 导出器 -> 接收器 -> 处理器 -> 导出器


这里直接怎么装配的呢？ 可以通过配置文件来装配，这就要看配置文件如何处理了


```

### ai 

### 异步数据处理(provider-consumer)

可以通过轮询的方式，将数据写入不同的chan中，这个有点类似于kafka中的partition(分区内有序)

启动多个协程去消费多个chan，一个协程消费一个chan (chan是没有缓存的) 写入数据后，还没有被及时消费，就会阻塞写； 消费后没有及时写入，阻塞消费

### io.read 需要添加limit限制
```go
reqBody, err := io.ReadAll(io.LimitReader(r.Body, 4*1024*1024))
```

### prometheus 的go client
```go
github.com/prometheus/client_golang v1.20.5
github.com/prometheus/common v0.61.0
github.com/prometheus/prometheus v0.48.1
```

```go
import (
"github.com/prometheus/client_golang/api"
)

promClient, err := api.NewClient(api.Config{
    Address: config.URL,
    Client:  c,
})

var transport = &http.Transport{
Proxy:               http.ProxyFromEnvironment,
MaxIdleConnsPerHost: 10000,
MaxConnsPerHost:     10000,
DialContext: (&net.Dialer{
Timeout:   30 * time.Second,
KeepAlive: 30 * time.Second,
}).DialContext,
ForceAttemptHTTP2:     true,
IdleConnTimeout:       90 * time.Second,
TLSHandshakeTimeout:   10 * time.Second,
ExpectContinueTimeout: 10 * time.Second,
ResponseHeaderTimeout: 30 * time.Second,
}
```

### 可观测指标

#### 场景1，对于使用线程池处理业务的场景
观察线程池内部的运行情况
1、正在运行的worker数量，占总数据量的百分比  -- 可以通过gauge 仪表盘观察(可增可减)
2、线程池的等待chan的占用率 -- 可以通过gauge，仪表盘观察
3、日志输出，将线程池的内部情况打印出来，便于观察其运行情况：正在运行的worker数量、总worker数量、等待channel的容量大小，channel的使用大小



### 优雅关闭channel 包含：有缓存的channel和无缓存的channel

#### 关闭有缓存的channel
针对于有缓存的channel我们不能在在组件声明周期结束的时候，直接就退出goroutine，这样会导致channel中剩余的数据无法消费

正确的操作应该是：
```text
1、关闭生产者 - 不再往channel中生产数据
2、close channel，保证执行完channel的goroutine能正常退出
3、等待执行goroutine执行完任务，sync.waitGroup; 这里需要做的是，每启动一个goroutine都需要添加一个wait等待
```

场景：

这种场景下，在组件关闭时，关闭channel，goroutine消费完channel中的数据后，就会正常退出
```go

a := make(chan string,10)
wg := sync.WaitGroup{}

wg.add(1)
go func() {
	defer wg.Done()
	for v range a {
        // consumer 
     }
}
}
```


这种场景，当cansel执行时，就会退出，如果channel中还有数据，就会丢失
```go
a := make(chan string,10)
wg := sync.WaitGroup{}

wg.add(1)
go func() {
    defer wg.Done()
	for {
		select {
		  case <- a:  
		     // do something
		  case <- ctx.Done():
			  // exit
			  break
} 
		
}
}


```