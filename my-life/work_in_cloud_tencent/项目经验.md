

### 告警检测
基于流式判断上报数据是否和控制台配置的策略中配置的规则是否匹配，如果匹配，那么就需要告警 -- 当然这里面还有其他的规则，比如复合条件的告警，需要多个条件满足

数据库表设计：
分表： 根据不同的地域将数据库中的数据按照地域分开
    策略表，规则表，实例表（filter）；一个策略可以绑定多个地域下的实例，那么就会在同步器同步到检测库中时，写到不同的地域表中
-- 这里说一下分表的好处
    1、策略数据量大，在写入和读取的时候压力会增大；分表后，数据散落到各个地域表中
    2、提升查询性能：降低锁竞争
    3、提高系统的可用性：故障隔离、平滑扩容（新开区）

-- 这里就存在新开区的问题，和在分表时，数据如何迁移的问题
```text
在分表时，数据是如何迁移的，在不影响业务的情况下，如何分表

数据库层面：
    1、存量数据：数据迁移，将不同地域的数据拷贝到各个地域表中
    2、增量数据：为了保证业务可以回滚，在db层写数据时，需要实现双写，保证在切流时，如果有问题，可以回滚（把流量切回去），不至于服务异常

业务服务层：
    1、有比较合理的切流过程，即整体放流情况
    2、当前项目中以来于同步器写入数据，写入数据时需要双写
    
什么时候关闭双写：
    当各个地域的流量全部切完，且正常运行后，不再需要双写来保证数据时，就可以停止双写了
```


告警检测的匹配规则：

1、告警对象的匹配，即通过指标中的告警维度匹配策略绑定的实例告警维度： 告警对象 --> 策略 --> 告警规则  这里的查询是一个连表查询
因为告警检测为了快速匹配响应，所以所有（该地域）的策略、规则、实例（filter）都需要加载到内存中，

```text
优化前：内存中的数据结构
    策略信息：策略名称、策略备注、策略id、策略类型
    告警规则（数组）：多个告警规则   任意满足/全部满足
    告警对象（多个）：这个是告警维度描述的，比如
     [
      {"Function":"Equal","Field":"appid","Args":"1251763868"},
      {"Function":"Equal","Field":"projectid","Args":"0"},
      {"Function":"Equal","Field":"vm_uuid","Args":"ba53fdd0-7222-441e-8a71-9cdd031c0bbf"}
    ]

匹配规则是，通过循环遍历内存中的告警对象中的告警维度，通过判断Function类型是equal，in，或者其他的（select case的方式），然后比较字段和参数值是否匹配

这样的匹配方式是比较缓慢的，需要一层一层的比较（一个告警维度，一个告警维度的比较）

而且因为策略绑定实例是多对多的方式，所以一个实例可以被多个策略绑定，一个策略可以绑定多个实例；所以要比较完所有的数据


优化后：内存中的数据结构 -- 主要是优化的告警对象的匹配规则
根据观察告警维度的Function的类型，发现90%的类型都是 equal和in的类型，那么这些类型有一个特点就是可以把所有的比较项组合起来

于是就将告警对象的维度表示分为两类，一种是可以通过告警维度计算hash的，一种是不能，只能全量匹配的

具体的解决思想是，通过空间换时间的概念，基于hashmap的O（1）的访问时间复杂度来处理，内部维护一个hashmap（目前使用的是本地缓存）
将告警维度的各个维度拼成字符串，并生成hash存放，value就是策略信息数组；（一个对象可能被绑定多个策略）--- 注意这里value只是策略对象的指针，并不是策略对象

检测到的告警指标中的实例的告警维度，也会进行判断是否可以生成taghash，如果可以生成taghash那么就计算出hash，快速匹配；
    如果不能计算taghash那么就只能按原来的方式匹配

将部分O(n)的匹配优化成了O（1）


```

2、告警规则匹配，通过告警指标值与匹配的告警策略中的告警规则匹配，看是否满足告警

```text
在通过告警对象的告警维度拿到符合条件的策略后，需要判断通过该策略的告警规则，判断该告警是否触发
  规则条件： > >= < <= = != 同比、环比

将这些规则封装成一个个对象，用于比较检测值和目标值，如果匹配就告警  -- 当然这里需要判断是否需要一些上下文的信息，比如所有规则满足时才告警（存放到redis中，共多个pod使用）


问题：比如一个策略里面有2个告警规则，规则A和规则B，告警触发的条件时规则A和规则B同时满足时才告警
    当规则A满足时，规则B不满足，此时将规则A的结果放入到redis中，当规则A不满足时，需要将redis中的数据给失效掉 --规则B也是如此；有且只有当规则A和规则B同时满足时才告警
    
    
告警检测中存在很多的判断：
    1、规则是否匹配的判断，会写redis，失效redis
    2、一个告警是触发还是恢复的判断；比如满足告警就发送告警，不满足告警且之前有告警，那么就是恢复告警 -- 这些状态都是存放到redis中的
    3、告警升级、降级的判断： 判断不同的告警规则触发的级别

```


3、告警策略、告警规则、告警对象（filter）是如何加载到内存中，如何更新的
```text
pod 启动时，加载数据库中的数据到告警检测服务的内存中

增量数据，定时任务一分钟粒度；因为数据表数据都有一个版本号的字段（本质就是一个时间戳），每次的定时任务只需要拿符合条件的最新数据即可；然后将最新的数据更新到内存中（当然需要维护内部的数据结构）

```
4、告警检测数据库中的数据是怎么来的？
```text
告警检测数据库和可观测控制台创建策略的数据库是分开的，是两个数据库；所以在数据同步上，依赖一个数据同步器服务来支持

全量同步：每天定时全量同步数据；保证两边数据库数据的一致性（最终一致性），也支持手动启动全量同步，主要是用于解决增量同步慢，阻塞数据的场景

增量同步：基于canal + kafka 方案；通过监听mysql的binlog文件（row模式），为了保证数据的有序性，所以在同步的过程中都是使用的单kafka分区，单业务线程做的
        同时业务不是单纯的db同步，存在业务(网络io等)，使整体慢下来
    
存在的问题时： 
当时有同事，一条delete操作，导致同步器的数据量激增，然后导致kafka中的数据阻塞，监控告警，人工介入处理，开启全量同步，全量同步后，增量同步时，只需要比较版本号即可，没有后面的业务逻辑了
原因是：delete操作，删除多行，然后因为是row模式，导致影响的数据增多
```

5、即便按照地域分表后，但是对于一些大地域的热门产品的数据量还是很多，为了尽可能减少数据之间影响和出现问题时的影响范围，支持可配置的方式将某地域的某些产品再部署到不同的pod中处理
    这样做的好处有如下：
        1、因为某个地域下的策略、规则、告警对象都是加载到内存中的，如果策略多了，对内存要求高，而pod在重启、升级时，大资源比小资源更难申请，最差情况下还会申请资源失败
        2、这也相当于是地域下的数据分流了，减少了数据之间的相互影响

6、默认策略告警场景，基于kafka的主题分流数据，保证数据之间不会相互影响

7、在告警历史的场景存在一个该失效告警历史，却没有失效的问题
```text
告警历史没有失效问题的引入是因为：失效告警历史的行为被分散到各个服务中了，又由于各个服务之间存在时序问题，这样就会导致被数据的告警历史数据，又会被改成触发中状态

解决方案是，在告警历史中新增一个字段（）
```